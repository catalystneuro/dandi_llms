{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer ontology grounded metadata from an abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Motivation\n",
    "We want to infer ontology grounded metadata from an abstract. This will both facilitate and improve automatic annotation in the archive.\n",
    "\n",
    "## Plan of action\n",
    "\n",
    "The main input to the pipeline should be either a doi or an abstract in plain text from which relevant information is to be extracted.\n",
    "\n",
    "There are two main steps to this process:\n",
    "1) Use LLMs as a Named Entity Recognition (NER) tool to identify ontology grounded entities in the abstract. This technique is based on [recent research](https://ar5iv.labs.arxiv.org/html/2304.10428). More specifically, the technique that we use is in-context learning, where a set of relevant examples are presented as context or instructions for inference to tailor a pre-trained language model to a specific task. The core of this \n",
    "technique is the selection of relevant examples to be used as context which instruct the LLM the schema of the desired response. The output of this step is a set of entities in plain language (e.g. mouse, fly, etc).\n",
    "\n",
    "2) LLMs tend to allucinate results which is not acceptable in the context of provenance and metadata annotation. In order to ground the results and constrain them to specific ontologies we semantically map the extracted entities in step 1 to specific identifiers extract from relevant ontologies (e.g. Uberon, NCBI Taxonomy, etc.). More in detail, for each relevant ontology we create a vector database for each of the ontology identifiers that contains a semantic representation of the identifier. We then use the extracted entities from step 1 to query the vector database and find the most similar ontology identifier. The output of this step is a set of ontology identifiers (e.g. UBERON:0000001, NCBITaxon:0000001, etc) Some [related approaches](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2678-8) to combine ontologies with LLMs have been tried before in the literature.\n",
    "\n",
    "\n",
    "A general overview of the pipeline is shown in the figure below:\n",
    "<img src=\"metadata_extraction.svg\" style=\"width: 1200px;\" />\n",
    "\n",
    "\n",
    "## Infrastructure and technical implementation\n",
    "\n",
    "This notebook is meant to showcase a proof of concept of the pipeline. The current implementation is based on a limited number of well annotated examples to be used in context learning and has a limited number of ontologies to be used for semantic mapping. So far, we have implemented two ontologies as vector databases in [Qdrant](https://qdrant.tech/) which we use both as a data model and a hosting solution. The first for Uberon which is based on the latest release and has been vectorized in full using the help of the [obonet](https://pypi.org/project/obonet/) project. The second is for NCBI Taxonomy which is based on the latest release and has been vectorized for [vertebrata](https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Info&id=7742) only and has been parsed using tools provided with the help of [etetoolkit](http://etetoolkit.org/). For LLM technologies, we have used [OpenAI functions](https://openai.com/blog/function-calling-and-other-api-updates). More specifically, we have used `OpenAI ada-002` as an embeding solution and `gpt-3.5-turbo` as an auto-completition agent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from pathlib import Path\n",
    "import os \n",
    "\n",
    "from repo_secrets import OPENAI_API_KEY\n",
    "from repo_secrets import QDRANT_API_KEY\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"QDRANT_API_KEY\"] = QDRANT_API_KEY\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metadata_extraction import generate_prompt_examples, generate_task_prompt_from_abstract, infer_metadata, generate_prompt_from_dandiset_id\n",
    "from utils.metadata_extraction import get_crossref_abstract\n",
    "from utils.metadata_extraction import ground_metadata_in_ontologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load context prompt built with examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are a neuroscience researcher and you are interested in figuring the '\n",
      " 'metadata from abstracts. Here are some examples of how you work:\\n'\n",
      " '- Example 1: The abstract of the paper is:\\n'\n",
      " '    Understanding how excitatory (E) and inhibitory (I) inputs are '\n",
      " 'integrated by neurons requires monitoring their subthreshold behavior. We '\n",
      " 'probed the subthreshold dynamics using optogenetic depolarizing pulses in '\n",
      " 'hippocampal neuronal assemblies in freely moving mice. Excitability '\n",
      " 'decreased during sharp-wave ripples coupled with increased I. In contrast to '\n",
      " 'this “negative gain,” optogenetic probing showed increased within-field '\n",
      " 'excitability in place cells by weakening I and unmasked stable place fields '\n",
      " 'in initially non–place cells. Neuronal assemblies active during sharp-wave '\n",
      " 'ripples in the home cage predicted spatial overlap and sequences of place '\n",
      " 'fields of both place cells and unmasked preexisting place fields of '\n",
      " 'non–place cells during track running. Thus, indirect probing of subthreshold '\n",
      " 'dynamics in neuronal populations permits the disclosing of preexisting '\n",
      " 'assemblies and modes of neuronal operations. \\n'\n",
      " '    Information: {\"species_names\": [\"Mus musculus - House mouse\"], '\n",
      " '\"anatomy\": [\"hippocampus\"], \"approach_names\": [\"behavioral approach\", '\n",
      " '\"electrophysiological approach\", \"optogenetic approach\"], '\n",
      " '\"measurement_names\": [\"spike sorting technique\", \"behavioral technique\", '\n",
      " '\"signal filtering technique\", \"analytical technique\", \"surgical technique\", '\n",
      " '\"multi electrode extracellular electrophysiology recording technique\"]}\\n'\n",
      " '    \\n'\n",
      " '- Example 2: The abstract of the paper is:\\n'\n",
      " '    Whereas progress has been made in identifying neural signals related to '\n",
      " 'rapid, cued decisions1–4, less is known about how brains guide and terminate '\n",
      " 'more ethologically relevant deliberations, where an animal’s own behavior '\n",
      " 'governs the options experienced over minutes5–8. Drosophila search for many '\n",
      " 'seconds to minutes for egg-laying sites with high relative value9, 10 and '\n",
      " 'neurons, called oviDNs, exist whose activity fulfills necessity and '\n",
      " 'sufficiency criteria for initiating the egg-deposition motor program11. Here '\n",
      " 'we show that oviDNs express a calcium signal that rises over seconds to '\n",
      " 'minutes as a fly deliberates whether to lay an egg. The calcium signal dips '\n",
      " 'when an egg is internally prepared (ovulated), rises at a rate related to '\n",
      " 'the relative value of the current substrate being experienced, and reaches a '\n",
      " 'consistent peak just prior to the abdomen bend for egg deposition. We '\n",
      " 'provide perturbational evidence that the egg-deposition motor program is '\n",
      " 'initiated once this signal hits a threshold and that sub-threshold variation '\n",
      " 'in the signal regulates the time spent deliberating and, ultimately, the '\n",
      " 'option chosen. These results argue that a rise-to-threshold signal guides '\n",
      " 'Drosophila to lay eggs on substrate options with high relative value, with '\n",
      " 'each egg-laying event representing a self-paced decision similar to '\n",
      " 'real-world decisions made by humans and other mammals. \\n'\n",
      " '    Information: {\"species_names\": [\"Drosophila melanogaster - Fruit fly\"], '\n",
      " '\"anatomy\": [], \"approach_names\": [\"behavioral approach\"], '\n",
      " '\"measurement_names\": [\"behavioral technique\", \"analytical technique\"]}\\n'\n",
      " '    \\n'\n",
      " '- Example 3: The abstract of the paper is:\\n'\n",
      " '    Neural plasticity allows us to learn skills and incorporate new '\n",
      " 'experiences. What happens when our lived experiences fundamentally change, '\n",
      " 'such as after a severe injury? To address this question, we analyzed '\n",
      " 'intracortical population activity in the posterior parietal cortex (PPC) of '\n",
      " 'a tetraplegic adult as she controlled a virtual hand through a '\n",
      " 'brain–computer interface (BCI). By attempting to move her fingers, she could '\n",
      " 'accurately drive the corresponding virtual fingers. Neural activity during '\n",
      " 'finger movements exhibited robust representational structure similar to fMRI '\n",
      " 'recordings of able-bodied individuals’ motor cortex, which is known to '\n",
      " 'reflect able-bodied usage patterns. The finger representational structure '\n",
      " 'was consistent throughout multiple sessions, even though the structure '\n",
      " 'contributed to BCI decoding errors. Within individual BCI movements, the '\n",
      " 'representational structure was dynamic, first resembling muscle activation '\n",
      " 'patterns and then resembling the anticipated sensory consequences. Our '\n",
      " 'results reveal that motor representations in PPC reflect able-bodied motor '\n",
      " 'usage patterns even after paralysis, and BCIs can re-engage these stable '\n",
      " 'representations to restore lost motor functions. \\n'\n",
      " '    Information: {\"species_names\": [\"Homo sapiens - Human\"], \"anatomy\": '\n",
      " '[\"posterior parietal cortex\"], \"approach_names\": [\"electrophysiological '\n",
      " 'approach\"], \"measurement_names\": [\"spike sorting technique\", \"surgical '\n",
      " 'technique\"]}\\n'\n",
      " '    \\n'\n",
      " '- Example 4: The abstract of the paper is:\\n'\n",
      " '    Proprioception, the sense of body position, movement, and associated '\n",
      " 'forces, remains poorly understood, despite its critical role in movement. '\n",
      " 'Most studies of area 2, a proprioceptive area of somatosensory cortex, have '\n",
      " 'simply compared neurons’ activities to the movement of the hand through '\n",
      " 'space. Using motion tracking, we sought to elaborate this relationship by '\n",
      " 'characterizing how area 2 activity relates to whole arm movements. We found '\n",
      " 'that a whole-arm model, unlike classic models, successfully predicted how '\n",
      " 'features of neural activity changed as monkeys reached to targets in two '\n",
      " 'workspaces. However, when we then evaluated this whole-arm model across '\n",
      " 'active and passive movements, we found that many neurons did not '\n",
      " 'consistently represent the whole arm over both conditions. These results '\n",
      " 'suggest that 1) neural activity in area 2 includes representation of the '\n",
      " 'whole arm during reaching and 2) many of these neurons represented limb '\n",
      " 'state differently during active and passive movements. \\n'\n",
      " '    Information: {\"species_names\": [\"Rhesus monkey\"], \"anatomy\": '\n",
      " '[\"Somatosensory area 2\"], \"approach_names\": [\"electrophysiological '\n",
      " 'approach\", \"behavioral approach\"], \"measurement_names\": [\"surgical '\n",
      " 'technique\", \"spike sorting technique\", \"analytical technique\", \"behavioral '\n",
      " 'technique\"]}\\n'\n",
      " '    \\n'\n",
      " '- Example 5: The abstract of the paper is:\\n'\n",
      " '    Motor behaviors are central to many functions and dysfunctions of the '\n",
      " 'brain, and understanding their neural basis has consequently been a major '\n",
      " 'focus in neuroscience. However, most studies of motor behaviors have been '\n",
      " 'restricted to artificial, repetitive paradigms, far removed from natural '\n",
      " 'movements performed “in the wild.” Here, we leveraged recent advances in '\n",
      " 'machine learning and computer vision to analyze intracranial recordings from '\n",
      " '12 human subjects during thousands of spontaneous, unstructured arm reach '\n",
      " 'movements, observed over several days for each subject. These naturalistic '\n",
      " 'movements elicited cortical spectral power patterns consistent with findings '\n",
      " 'from controlled paradigms, but with considerable neural variability across '\n",
      " 'subjects and events. We modeled interevent variability using 10 behavioral '\n",
      " 'and environmental features; the most important features explaining this '\n",
      " 'variability were reach angle and day of recording. Our work is among the '\n",
      " 'first studies connecting behavioral and neural variability across cortex in '\n",
      " 'humans during unstructured movements and contributes to our understanding of '\n",
      " 'long-term naturalistic behavior. \\n'\n",
      " '    Information: {\"species_names\": [\"Human\"], \"anatomy\": [\"primary motor '\n",
      " 'cortex\"], \"approach_names\": [\"behavioral approach\", \"electrophysiological '\n",
      " 'approach\"], \"measurement_names\": [\"behavioral technique\", \"multi electrode '\n",
      " 'extracellular electrophysiology recording technique\", \"analytical '\n",
      " 'technique\", \"surgical technique\"]}\\n'\n",
      " '    \\n'\n",
      " '- Example 6: The abstract of the paper is:\\n'\n",
      " '    Do neural activity patterns during sleep reflect the replay of a novel '\n",
      " 'experience or an invariant preexisting dynamic? Grosmark and Buzsáki '\n",
      " 'observed that both familiar and novel aspects of learned information are '\n",
      " 'replayed during synchronous bursts of activity in the hippocampus. '\n",
      " 'Familiarity was encoded by fast-firing less-modifiable neurons that showed '\n",
      " 'rate and sequence correlations that persisted into postlearning sleep. The '\n",
      " 'novel features of an experience were represented by a different set of '\n",
      " 'slowly firing and highly plastic cells. \\n'\n",
      " '    Information: {\"species_names\": [\"Brown rat\"], \"anatomy\": [], '\n",
      " '\"approach_names\": [\"electrophysiological approach\"], \"measurement_names\": '\n",
      " '[\"signal filtering technique\", \"multi electrode extracellular '\n",
      " 'electrophysiology recording technique\", \"spike sorting technique\"]}\\n'\n",
      " '    ')\n"
     ]
    }
   ],
   "source": [
    "instructions_prompt = \"\"\"You are a neuroscience researcher and you are interested in figuring the metadata from abstracts. Here are some examples of how you work:\"\"\"\n",
    "\n",
    "training_dadiset_ids = [\"000568\", \"000250\", \"000147\", \"000127\", \"000055\", \"000044\"]\n",
    "context_examples = generate_prompt_examples(training_dadiset_ids)\n",
    "\n",
    "context_prompt = instructions_prompt + context_examples\n",
    "pprint.pprint(context_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 from DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Abstract: \n",
      "\n",
      "('Basal forebrain cholinergic neurons modulate how organisms process and '\n",
      " 'respond to environmental stimuli through impacts on arousal, attention, and '\n",
      " 'memory. It is unknown, however, whether basal forebrain cholinergic neurons '\n",
      " 'are directly involved in conditioned behavior, independent of secondary '\n",
      " 'roles in the processing of external stimuli. Using fluorescent imaging, we '\n",
      " 'found that cholinergic neurons are active during behavioral responding for a '\n",
      " 'reward – even in prior to reward delivery and in the absence of discrete '\n",
      " 'stimuli. Photostimulation of basal forebrain cholinergic neurons, or their '\n",
      " 'terminals in the basolateral amygdala (BLA), selectively promoted '\n",
      " 'conditioned responding (licking), but not unconditioned behavior nor innate '\n",
      " 'motor outputs. In vivo electrophysiological recordings during cholinergic '\n",
      " 'photostimulation revealed reward-contingency-dependent suppression of BLA '\n",
      " 'neural activity, but not prefrontal cortex (PFC). Finally, ex vivo '\n",
      " 'experiments demonstrated that photostimulation of cholinergic terminals '\n",
      " 'suppressed BLA projection neuron activity via monosynaptic '\n",
      " 'muscarinic-receptor-signaling, while also facilitating firing in GABAergic '\n",
      " 'interneurons. Taken together, we show that the neural and behavioral effects '\n",
      " 'of basal forebrain cholinergic activation are modulated by reward '\n",
      " 'contingency in a target-specific manner.')\n"
     ]
    }
   ],
   "source": [
    "# Random article from elife\n",
    "doi = \"https://doi.org/10.7554/eLife.89093.1\" \n",
    "abstract_to_test = get_crossref_abstract(doi)\n",
    "\n",
    "print(\"\\n Abstract: \\n\")\n",
    "pprint.pprint(abstract_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Information extracted: \n",
      "\n",
      "{'anatomy': ['basal forebrain cholinergic neurons',\n",
      "             'basolateral amygdala',\n",
      "             'prefrontal cortex'],\n",
      " 'approach_names': ['fluorescent imaging', 'electrophysiological approach'],\n",
      " 'measurement_names': ['surgical technique',\n",
      "                       'signal filtering technique',\n",
      "                       'multi electrode extracellular electrophysiology '\n",
      "                       'recording technique'],\n",
      " 'species_names': []}\n"
     ]
    }
   ],
   "source": [
    "task_prompt = generate_task_prompt_from_abstract(abstract_to_test)\n",
    "prompt = f\"{context_prompt} {task_prompt}\"\n",
    "plain_metadata = infer_metadata(prompt)\n",
    "\n",
    "print(\"\\n Information extracted: \\n\")\n",
    "pprint.pprint(plain_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Information extracted: \n",
      "\n",
      "{'anatomy': ['basal forebrain cholinergic neurons',\n",
      "             'basolateral amygdala',\n",
      "             'prefrontal cortex'],\n",
      " 'approach_names': ['fluorescent imaging', 'electrophysiological approach'],\n",
      " 'measurement_names': ['surgical technique',\n",
      "                       'signal filtering technique',\n",
      "                       'multi electrode extracellular electrophysiology '\n",
      "                       'recording technique'],\n",
      " 'species_names': []}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Information extracted: \\n\")\n",
    "pprint.pprint(plain_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'species_names': [],\n",
       " 'anatomy': ['basal forebrain cholinergic neurons',\n",
       "  'basolateral amygdala',\n",
       "  'prefrontal cortex'],\n",
       " 'approach_names': ['fluorescent imaging', 'electrophysiological approach'],\n",
       " 'measurement_names': ['surgical technique',\n",
       "  'signal filtering technique',\n",
       "  'multi electrode extracellular electrophysiology recording technique'],\n",
       " 'anatomy_identifiers': ['UBERON:0002743', 'UBERON:0002887', 'UBERON:0000451'],\n",
       " 'anatomy_urls': ['http://purl.obolibrary.org/obo/UBERON_0002743',\n",
       "  'http://purl.obolibrary.org/obo/UBERON_0002887',\n",
       "  'http://purl.obolibrary.org/obo/UBERON_0000451']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grounded_metadata = ground_metadata_in_ontologies(plain_metadata)\n",
    "grounded_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example two from abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Abstract: \n",
      "\n",
      "('The relationship between mesoscopic local field potentials (LFPs) and '\n",
      " 'single-neuron firing in the multi-layered neocortex is poorly understood. '\n",
      " 'Simultaneous recordings from all layers in the primary visual cortex (V1) of '\n",
      " 'the behaving mouse revealed functionally defined layers in V1. The depth of '\n",
      " 'maximum spike power and sink-source distributions of LFPs provided '\n",
      " 'consistent laminar landmarks across animals. Coherence of gamma oscillations '\n",
      " '(30-100 Hz) and spike-LFP coupling identified six physiological layers and '\n",
      " 'further sublayers. Firing rates, burstiness, and other electrophysiological '\n",
      " 'features of neurons displayed unique layer and brain state dependence. Spike '\n",
      " 'transmission strength from layer 2/3 cells to layer 5 pyramidal cells and '\n",
      " 'interneurons was stronger during waking compared with non-REM sleep but '\n",
      " 'stronger during non-REM sleep among deep-layer excitatory neurons. A subset '\n",
      " 'of deep-layer neurons was active exclusively in the DOWN state of non-REM '\n",
      " 'sleep. These results bridge mesoscopic LFPs and single-neuron interactions '\n",
      " 'with laminar structure in V1.')\n"
     ]
    }
   ],
   "source": [
    "# Random article from elife\n",
    "abstract_to_test = \"\"\"The relationship between mesoscopic local field potentials (LFPs) and single-neuron firing in the multi-layered neocortex is poorly understood. Simultaneous recordings from all layers in the primary visual cortex (V1) of the behaving mouse revealed functionally defined layers in V1. The depth of maximum spike power and sink-source distributions of LFPs provided consistent laminar landmarks across animals. Coherence of gamma oscillations (30-100 Hz) and spike-LFP coupling identified six physiological layers and further sublayers. Firing rates, burstiness, and other electrophysiological features of neurons displayed unique layer and brain state dependence. Spike transmission strength from layer 2/3 cells to layer 5 pyramidal cells and interneurons was stronger during waking compared with non-REM sleep but stronger during non-REM sleep among deep-layer excitatory neurons. A subset of deep-layer neurons was active exclusively in the DOWN state of non-REM sleep. These results bridge mesoscopic LFPs and single-neuron interactions with laminar structure in V1.\"\"\"\n",
    "\n",
    "print(\"\\n Abstract: \\n\")\n",
    "pprint.pprint(abstract_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Information extracted: \n",
      "\n",
      "{'anatomy': ['primary visual cortex (V1)'],\n",
      " 'approach_names': ['electrophysiological approach'],\n",
      " 'measurement_names': ['multi electrode extracellular electrophysiology '\n",
      "                       'recording technique',\n",
      "                       'spike sorting technique',\n",
      "                       'signal filtering technique'],\n",
      " 'species_names': ['Mus musculus - House mouse']}\n"
     ]
    }
   ],
   "source": [
    "task_prompt = generate_task_prompt_from_abstract(abstract_to_test)\n",
    "prompt = f\"{context_prompt} {task_prompt}\"\n",
    "plain_metadata = infer_metadata(prompt)\n",
    "\n",
    "print(\"\\n Information extracted: \\n\")\n",
    "pprint.pprint(plain_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anatomy': ['primary visual cortex (V1)'],\n",
      " 'anatomy_identifiers': ['UBERON:0002436'],\n",
      " 'anatomy_urls': ['http://purl.obolibrary.org/obo/UBERON_0002436'],\n",
      " 'approach_names': ['electrophysiological approach'],\n",
      " 'measurement_names': ['multi electrode extracellular electrophysiology '\n",
      "                       'recording technique',\n",
      "                       'spike sorting technique',\n",
      "                       'signal filtering technique'],\n",
      " 'species_identifiers': ['NCBITaxon:3004188'],\n",
      " 'species_names': ['Mus musculus - House mouse'],\n",
      " 'species_urls': ['http://purl.obolibrary.org/obo/NCBITaxon_3004188']}\n"
     ]
    }
   ],
   "source": [
    "grounded_metadata = ground_metadata_in_ontologies(plain_metadata)\n",
    "pprint.pprint(grounded_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anatomy': [],\n",
      " 'anatomy_identifiers': [],\n",
      " 'anatomy_urls': [],\n",
      " 'approach_names': ['imaging approach'],\n",
      " 'measurement_names': ['two-photon imaging technique'],\n",
      " 'species_identifiers': ['NCBITaxon:448761'],\n",
      " 'species_names': ['Drosophila melanogaster - Fruit fly'],\n",
      " 'species_urls': ['http://purl.obolibrary.org/obo/NCBITaxon_448761']}\n"
     ]
    }
   ],
   "source": [
    "# Random article from elife\n",
    "abstract_to_test = \"\"\"Walking is a fundamental mode of locomotion, yet its neural correlates are unknown at brain-\n",
    "wide scale in any animal. We use volumetric two-photon imaging to map neural activity\n",
    "associated with walking across the entire brain of Drosophila. We detect locomotor signals in\n",
    "approximately 40% of the brain, identify a global signal associated with the transition from rest\n",
    "to walking, and define clustered neural signals selectively associated with changes in forward or\n",
    "angular velocity. These networks span functionally diverse brain regions, and include regions\n",
    "that have not been previously linked to locomotion. We also identify time-varying trajectories of\n",
    "neural activity that anticipate future movements, and that represent sequential engagement of\n",
    "clusters of neurons with different behavioral selectivity. These motor maps suggest a dynamical\n",
    "systems framework for constructing walking maneuvers reminiscent of models of forelimb\n",
    "reaching in primates and set a foundation for understanding how local circuits interact across\n",
    "large-scale networks.\"\"\"\n",
    "\n",
    "task_prompt = generate_task_prompt_from_abstract(abstract_to_test)\n",
    "prompt = f\"{context_prompt} {task_prompt}\"\n",
    "\n",
    "plain_metadata = infer_metadata(prompt)\n",
    "grounded_metadata = ground_metadata_in_ontologies(plain_metadata)\n",
    "pprint.pprint(grounded_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix (to be deleted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to baselines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dandiset_id_test = \"000568\"\n",
    "doi = \"https://doi.org/10.1038/s41593-022-01138-x\" \n",
    "abstract_to_test = \"The incorporation of new information into the hippocampal network is likely to be constrained by its innate architecture and internally generated activity patterns. However, the origin, organization and consequences of such patterns remain poorly understood. In the present study we show that hippocampal network dynamics are affected by sequential neurogenesis. We birthdated CA1 pyramidal neurons with in utero electroporation over 4 embryonic days, encompassing the peak of hippocampal neurogenesis, and compared their functional features in freely moving adult mice. Neurons of the same birthdate displayed distinct connectivity, coactivity across brain states and assembly dynamics. Same-birthdate neurons exhibited overlapping spatial representations, which were maintained across different environments. Overall, the wiring and functional features of CA1 pyramidal neurons reflected a combination of birthdate and the rate of neurogenesis. These observations demonstrate that sequential neurogenesis during embryonic development shapes the preconfigured forms of adult network dynamics.\"\n",
    "task_prompt = generate_task_prompt_from_abstract(abstract_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = generate_task_prompt_from_abstract(abstract_to_test)\n",
    "context_prompt = preamble_prompt + zero_shot_prompt\n",
    "prompt = f\"{context_prompt} {task_prompt}\"\n",
    "\n",
    "print(\"abstract: \\n\")\n",
    "pprint.pprint(abstract_to_test)\n",
    "print(\"\\n Information extracted: \\n\")\n",
    "metadata = infer_metadata(prompt)\n",
    "pprint.pprint(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline without context learning for sanity check\n",
    "1) Same as our pipeline, but without context learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_prompt = preamble_prompt \n",
    "prompt = f\"{context_prompt} {task_prompt}\"\n",
    "\n",
    "print(\"abstract: \\n\")\n",
    "pprint.pprint(abstract_to_test)\n",
    "print(\"\\n Information extracted: \\n\")\n",
    "metadata = infer_metadata(prompt)\n",
    "pprint.pprint(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Better baseline\n",
    "For a comparision that is more fair, here we attempt to make the baseline better by using a more sophisticated prompt and more clear expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_task_prompt_from_abstract_without_context(abstract: str) -> str:\n",
    "    prompt = f\"\"\"The abstract of the paper is:\n",
    "    {abstract} \n",
    "\n",
    "    Extract the following information from the abstract:\n",
    "    - species:\n",
    "    - species identifier in the NCBI taxonomy:\n",
    "    - approach:\n",
    "    - measurement:\n",
    "    - anatomy:\n",
    "    - anatomy identifier in the Uberon ontology:\n",
    "\n",
    "    Return the response as a JSON object with the following format:\n",
    "    \n",
    "    {{\n",
    "        \"species\": [species_name_1, species_name_2, ...],\n",
    "        \"species_identifier\": [species identifiers in the NCBI taxonomy. e.g 'http://purl.obolibrary.org/obo/NCBITaxon_10090'],\n",
    "        \"approach\": [e.g. 'electrophysiology', 'calcium imaging', 'optogenetics'],\n",
    "        \"measurement\": [e.g. surgery, spike sorting, etc.],\n",
    "        \"anatomy\": [e.g. 'hippocampus', 'cortex', 'thalamus'],\n",
    "        \"anatomy_identifier\": [anatomy identifier in the Uberon ontology]\n",
    "    }}\n",
    "    \n",
    "    If some information is missing, leave it blank.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_prompt = preamble_prompt \n",
    "task_prompt = generate_task_prompt_from_abstract_without_context(abstract_to_test)\n",
    "prompt = f\"{context_prompt} {task_prompt}\"\n",
    "\n",
    "print(\"abstract: \\n\")\n",
    "pprint.pprint(abstract_to_test)\n",
    "print(\"\\n Information extracted: \\n\")\n",
    "metadata = infer_metadata(prompt)\n",
    "pprint.pprint(metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dandi_llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
