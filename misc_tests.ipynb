{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c00e453-b930-4256-923b-65f0f0d69336",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b9a5f-4055-4a29-835b-1cc76c450a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b1f8f-66f3-4948-b750-3a8a96b91d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(host=\"localhost\")\n",
    "vectordb = Qdrant(\n",
    "    client=qdrant_client, \n",
    "    collection_name=\"dandi_collection\",\n",
    "    embeddings=OpenAIEmbeddings(),\n",
    "    content_payload_key=\"text_content\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2c2f2-650f-48cd-a4ce-bf72a450f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.similarity_search(\"glial cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c401ae5-298a-418d-bb99-b7b8b751d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_queries = 3\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    llm=ChatOpenAI(temperature=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a161f3c9-9faf-42cb-9284-145849048c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I am interested in the tuning properties of glial cells. Are there any good dandisets for studying that?\"\n",
    "retriever_from_llm.generate_queries(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358c21e-2179-4a65-b78a-e5c240faa82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs = retriever_from_llm.get_relevant_documents(question=user_input)\n",
    "unique_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e7703c-f672-44e5-8783-b06d372b5f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d472939-957e-4b76-8539-4ac4d14f09bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d512ec-e67a-4bd7-a49e-550de89d3465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4789e421-3669-4281-88a3-407a79c089a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pipeline import suggest_relevant_dandisets\n",
    "from utils.openai import get_llm_chat_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b381463-0a0e-450d-85d1-f28e0b32410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most relevant dandisets for your question are:\n",
      "\n",
      "1. DANDISET:000055/draft - AJILE12: Long-term naturalistic human intracranial neural recordings and pose\n",
      "   This dandiset contains intracranial neural recordings and upper body pose trajectories of humans performing unstructured, spontaneous movements in completely naturalistic settings. The dataset includes synchronized neural recordings and pose trajectories, along with relevant metadata such as wrist movement events and annotated behavioral states. This dandiset uses an electrophysiological approach and includes multi-electrode extracellular electrophysiology recordings, providing insights into the neural basis of natural human movement.\n",
      "\n",
      "2. DANDISET:000540/draft - Dataset for: A change in behavioral state switches the pattern of motor output that underlies rhythmic head and orofacial movements\n",
      "   This dandiset provides recorded multi-modal data from rats performing naturalistic foraging and rearing behaviors. The dataset includes videography, respiration, electromyogram, wearable sensor signals, and human annotation, providing a comprehensive understanding of natural movement in rats. While this dandiset focuses on animal models, it employs a behavioral approach, which can offer insights into the underlying mechanisms of natural movement.\n",
      "\n",
      "3. DANDISET:000019/draft - Human ECoG speaking consonant-vowel syllables\n",
      "   This dandiset contains electrocorticography (ECoG) recordings from human patients during the performance of speaking tasks. The dataset includes voltage traces from a high-density array of electrodes, as well as detailed annotations of the spoken syllables. By analyzing the cortical activity during natural speech production, this dandiset can provide insights into the neural correlates of natural movement in humans.\n",
      "\n",
      "These dandisets offer a combination of electrophysiological and behavioral approaches to study natural movement in humans and animal models. They provide recordings and annotations that allow for comprehensive analyses of neural activity and behavioral patterns during naturalistic scenarios.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I want to study natural movement in humans\"\n",
    "\n",
    "suggestions = suggest_relevant_dandisets(user_input=user_input, model=\"gpt-3.5-turbo-16k\", method=1)\n",
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d14be8c-a6a7-4c52-991c-1f4414b4905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a helpful neuroscience programmer assistant, \n",
    "you help extract neuroscience methods information and write Python code for analysis\"\"\"\n",
    "\n",
    "prompt = \"\"\"Given the sample file structure, and the user's input, write a Python script that analysis this neurophysiology data. \n",
    "You can stream data from dandi archive like this:\n",
    "```\n",
    "import fsspec \n",
    "import h5py\n",
    "from pynwb import NWBHDF5IO\n",
    "fs = fsspec.filesystem(\"http\")\n",
    "f = fs.open(\"file_url\", \"rb\")\n",
    "file = h5py.File(f)\n",
    "io = NWBHDF5IO(file=file, mode=\"r\", load_namespaces=True)\n",
    "nwbfile = io.read()\n",
    "```\n",
    "---\n",
    "user input:\n",
    "I want to know if the occurence of a given event significantly influences the occurence of any next event.\n",
    "---\n",
    "file structure:\n",
    "nwbfile.acquisition =>\n",
    "{'BehavioralSyllable': BehavioralSyllable abc.LabeledEvents at 0x140407025449184\n",
    " Fields:\n",
    "   data: <HDF5 dataset \"data\": shape (53771,), type \"|u1\">\n",
    "   data__labels: ['Paw lick/scrunch' 'Pause' 'Pause, low rear' 'Pause' 'Scrunch'\n",
    "  'Paused low rear' 'High sniff' 'Turn left' 'Reared sniff' 'Reared sniff'\n",
    "  'High run' 'Rear/jump' 'Reared sniff' 'Body lick' 'Short run' 'Run'\n",
    "  'Short dart' 'Wall rear' 'Forward run' 'Orient left' 'Run' 'High sniff'\n",
    "  'Rear' 'Turn left' 'Rear up, turn left' 'Walk Forward' 'Pause'\n",
    "  'Rightward rear down' 'Dive down' 'Pause' 'Leftward rear down' 'Groom'\n",
    "  'Pause, turn left' 'Groom/paw lick' 'Orient right' 'Scrunch right' 'Rear'\n",
    "  'Uncommon Syllable (frequency < 1%)' 'Uncommon Syllable (frequency < 1%)'\n",
    "  'Uncommon Syllable (frequency < 1%)' 'Uncommon Syllable (frequency < 1%)'\n",
    "  'Uncommon Syllable (frequency < 1%)' 'Uncommon Syllable (frequency < 1%)'\n",
    "  'Uncommon Syllable (frequency < 1%)' 'Uncommon Syllable (frequency < 1%)'\n",
    "  'Uncommon Syllable (frequency < 1%)' 'Uncommon Syllable (frequency < 1%)'\n",
    "  'Uncommon Syllable (frequency < 1%)' 'Uncommon Syllable (frequency < 1%)'\n",
    "  'Uncommon Syllable (frequency < 1%)' 'Uncommon Syllable (frequency < 1%)'\n",
    "  'Uncommon Syllable (frequency < 1%)' 'Uncommon Syllable (frequency < 1%)'\n",
    "  'Uncommon Syllable (frequency < 1%)' 'Uncommon Syllable (frequency < 1%)'\n",
    "  'Uncommon Syllable (frequency < 1%)' 'Uncommon Syllable (frequency < 1%)'\n",
    "  'Uncommon Syllable (frequency < 1%)']\n",
    "   description: Behavioral Syllable identified by Motion Sequencing (MoSeq).\n",
    "   timestamps: <HDF5 dataset \"timestamps\": shape (53771,), type \"<f8\">\n",
    "   timestamps__unit: seconds}\n",
    "---\n",
    "Begin:\"\"\"\n",
    "\n",
    "r = get_llm_chat_answer(prompt=prompt, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89308288-fab1-4cf8-9166-ca362ec77b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To analyze whether the occurrence of a given event significantly influences the occurrence of any next event, we can perform a contingency table analysis using the data from the `BehavioralSyllable` acquisition.\n",
      "\n",
      "Here's a Python script that extracts the data and performs the contingency table analysis:\n",
      "\n",
      "```python\n",
      "import fsspec\n",
      "import h5py\n",
      "import numpy as np\n",
      "from scipy.stats import chi2_contingency\n",
      "\n",
      "# Stream data from DANDI archive\n",
      "file_url = \"URL_TO_NWB_FILE\"\n",
      "fs = fsspec.filesystem(\"http\")\n",
      "f = fs.open(file_url, \"rb\")\n",
      "file = h5py.File(f)\n",
      "\n",
      "# Get the data\n",
      "data = file[\"nwbfile\"][\"acquisition\"][\"BehavioralSyllable\"][\"data\"][:]\n",
      "labels = file[\"nwbfile\"][\"acquisition\"][\"BehavioralSyllable\"][\"data__labels\"][:]\n",
      "\n",
      "# Count occurrences of each event\n",
      "events, counts = np.unique(labels, return_counts=True)\n",
      "\n",
      "# Create contingency table\n",
      "contingency_table = np.zeros((len(events), len(events)))\n",
      "event_indices = {event: i for i, event in enumerate(events)}\n",
      "\n",
      "for i in range(len(labels) - 1):\n",
      "    current_event = labels[i]\n",
      "    next_event = labels[i + 1]\n",
      "    current_event_index = event_indices[current_event]\n",
      "    next_event_index = event_indices[next_event]\n",
      "    contingency_table[current_event_index][next_event_index] += 1\n",
      "\n",
      "# Perform chi-square test of independence on the contingency table\n",
      "_, p_value, _, _ = chi2_contingency(contingency_table)\n",
      "\n",
      "# Determine if the occurrence of the given event significantly influences the occurrence of any next event\n",
      "given_event = \"Given Event\"  # Replace with the desired event\n",
      "given_event_index = event_indices[given_event]\n",
      "significant = any(p_value[given_event_index] < 0.05 for p_value in p_value)\n",
      "\n",
      "if significant:\n",
      "    print(\"The occurrence of the given event significantly influences the occurrence of at least one next event.\")\n",
      "else:\n",
      "    print(\"The occurrence of the given event does not significantly influence the occurrence of any next event.\")\n",
      "```\n",
      "\n",
      "Make sure to replace `\"URL_TO_NWB_FILE\"` with the actual URL of the NWB file you want to analyze. Also, replace `\"Given Event\"` with the desired event for analysis. The script uses the `scipy.stats.chi2_contingency` function to perform the chi-square test of independence on the contingency table.\n",
      "\n",
      "This script will check if the occurrence of the given event significantly influences the occurrence of any next event based on a p-value threshold of 0.05. If the p-value is below the threshold for at least one next event, it will be considered significant.\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a8ec9-1074-4d3a-b6d9-9fe38556d8be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_gpt",
   "language": "python",
   "name": "env_gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
