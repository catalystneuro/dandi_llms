{
    "brezovec": "EXPERIMENTAL MODEL AND SUBJECT DETAILS\nDrosophila melanogaster were of the genotype w+/w+;UAS-myr::tdTomato/UAS-GCaMP6f;nSyb-Gal4/+. Flies were raised on molasses medium at 25 \u00b0C with a 12/12-h light/dark cycle. Flies were housed in mixed male/female vials of 10-20 individuals. 3-4 days post-eclosion females were used for imaging.\n\nMETHOD DETAILS\nMounting and Dissection\nEach fly was anesthetized on a chilled Peltier plate with a thermally coupled custom holder. Each immobilized fly was carefully fitted into a custom mount consisting of 3D-printed plastic and a custom cut steel shim to tightly nestle the head and thorax. To fix the fly to the mount, UV-curable glue was placed and cured on the dorsal region of the face between the eyes, and on the thorax. A saline solution was added to the dish for dissection (103 mM NaCl, 3 mM KCl, 5 mM TES, 1 mM NaH2PO4, 4 mM MgCl2, 1.5 mM CaCl2, 10 mM trehalose, 10 mM glucose, 7 mM sucrose, and 26 mM NaHCO3). Using a tungsten needle the posterior head cuticle was carefully cut and removed to reveal the whole brain (Figure S1). Dissection forceps were used to remove fat and trachea.\n\nTwo-Photon Imaging\nFlies were imaged using a resonant scanning Bruker Ultima IV system with a piezo drive and a Leica 20\u00d7 HCX APO 1.0 NA water immersion objective lens. GCaMP6f and tdTomato were simultaneously excited with a Chameleon Vision II femtosecond laser (Coherent) at 920 nm. A 525/50 nm filter and a 550/50 nm filter were used to collect signals from GCaMP6f and tdTomato. Photons were detected simultaneously using two GaAsP-type photomultiplier tubes. The exposed fly brain was perfused with carbogen-bubbled (95% O2, 5% CO2) saline solution (same as above) heated to 30\u00b0C with an in-line heater. For the 30 min functional scan, volumes were collected at a resolution of 2.6 \u00d7 2.6 \u00d7 5 \u00b5m (256 voxels x 128 voxels x 49 slices, XYZ), resulting in an approximate volume rate of 1.8Hz. Scans were bidirectional along the X axis. For the immediately subsequent anatomical scan, spatial dimensions were adjusted to 0.6 \u00d7 0.6 \u00d7 1\u00b5m (1024 voxels x 512 voxels x 241 slices, XYZ), and 100 volumes were collected. In this orientation, all regions of the brain were visible, except for the laminas in each optic lobe, which are occluded by the eye, and a portion of the Gnathal Ganglion, which is occluded by the esophagus.\n\nBehavior Tracking\nDuring imaging, the head-fixed fly performed spontaneous bouts of walking on a painted, air-suspended foam ball (9 mm diameter, LAST-A-FOAM FR4615). The ball was imaged at 50 Hz with a Flea FL3-U3-13E4M-C sensor and Edmund Optics 100 mm C Series Fixed Focal Length Lens. An IR LED directed with optic fibers was used to illuminate the ball. Frames were processed using Fictrac to calculate the animal\u2019s walking velocity (Moore et al., 2014). Before all subsequent analysis, forward and rotational velocities were smoothed with a Savitzky-Golay filter of window length 500 ms and a polynomial of order 3.\n\nData Preprocessing\nBrain volumes were first motion-corrected using ANTs (Avants et al., 2009; Avants et al., 2011); the tdTomato channel was time-averaged across the 30 min recording and each tdTomato volume was warped (affine and non-linear) to the mean. Each volume\u2019s warp parameters were then applied to the GCaMP6f channel. Then, each voxel was independently corrected for bleaching as well as other slow temporal trends by subtracting a temporally smoothed signal from the raw trace (smooth signal produced by gaussian filter of 2 minute sigma, truncated at 1 sigma). Finally, each voxel in the GCaMP6f recording was Z-scored. This preprocessing was all done on individual animals before volumetric alignment and concatenation.",
    "valero": "\nAnimals were housed on a 12-hour reverse light/dark cycle, and the recording session\nstarted 1-2 hr after the onset of the dark phase. We recorded from the mice while they slept or\nwalked around freely in the home cage. Electrophysiological data were acquired using an Intan\nRHD2000 system (Intan Technologies LLC) digitized with 30 kHz rate. The wide-band signal\nwas downsampled to 1.25 kHz and used as the LFP signal. The animal\u2019s position was monitored\nwith a Basler camera (acA1300-60 gmNIR, Graftek Imaging) sampling at 30Hz to detect a headmounted red LEDs. Position was synchronized with neural data with TTLs signaling shutter\nposition. Animals were handled daily and accommodated to the experimenter, recording room\nand cables for 1 week before the start of the experiments. Water access was restricted and was\nonly available as reward on a linear track, ad libitum for 30 minutes at the end of each\nexperimental day and ad libitum for one full non-experimental day per week. Mice were trained\nto run laps in a PVC linear track (110 cm long, 6.35 cm wide) to retrieve water reward (5-10\u00b5L)\nat each end. Water delivery and optogenetic stimuli during track were controlled by a custommade, Arduino-based circuit (circuits and software are available in\n. For a typical recording session, mice were recorded \n3\ncontinuously for ~300 min through 6 experimental blocks (see Fig. S7D): pre track-baseline\n(Pre-baseline, 60 min), Pre-track stimulation (Pre-stim, 60 min), Linear Maze task, post trackstimulation (Post Stim) and Post-track baseline. During track running, 3 baseline (nostimulation) blocks (10 trials each) were interleaved with two stimulation blocks (40 to 60 trials).\n",
    "jagger": "\nMick Jagger (born 26 July 1943) is an English singer and songwriter. He was born and grew up in Dartford, joining the rock band the Rolling Stones in 1962 as the lead vocalist and a founder member. His songwriting partnership with Keith Richards is one of history's most successful. A pioneer of the modern music industry, Jagger has been widely described as one of the most popular and influential frontmen in rock music history. Notorious for his romantic involvements and illicit drug use, he has often been portrayed as a countercultural figure. \n",
    "gibberish": "\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
    "dandi_00397": " \nAll patients voluntarily participated after informed consent according to guidelines as monitored by the Massachusetts General Brigham (previously Partners) Institutional Review Board (IRB) Massachusetts General Hospital (MGH). Participants were informed that participation in the experiment would not alter their clinical treatment in any way, and that they could withdraw at any time without jeopardizing their clinical care. Participants were not compensated monetarily for participating. Recordings in the operating room were acquired with 9 participants (mean= 59 years old, ranging from 34 to 75; 7 female) who were already scheduled for a craniotomy for concurrent clinical intraoperative neurophysiological monitoring or testing for mapping motor, language, and sensory regions and removal of tissue as a result of tumor or epilepsy or undergo intra-operative neurophysiology as part of their planned deep brain stimulator (DBS) placement. Prior to inserting the Neuropixels probe, a small superficial incision in the pia was done using an arachnoid surgical knife. The Neuropixels probe was inserted through this incision. Recordings were referenced to sterile ground and recording reference needle electrodes (Medtronic) placed in nearby muscle tissue (often scalp) as deemed safe by the neurosurgical team though a series of tests ground and reference tests were performed to identify the ideal combinations of ground and reference options\n",
    "dandi_00249": "\nTwo behavioral tasks\nWe trained two groups of mice to perform one of two tasks: shape discrimination (concave vs convex) or shape detection (either of those shapes, vs nothing). Mice were placed on a regulated water schedule to motivate them to perform the task to obtain water rewards. For each session, they were head-fixed and trained to lick either a left lickpipe or a right lickpipe in front of their face, depending on the presented stimulus. Shape discrimination mice were trained to lick left for concave shapes and right for convex shapes. Shape detection mice were trained to lick right for either shape (concave or convex) and to lick left on catch trials when no shape was presented at all. No mice were trained on both tasks.\n\nOn each trial, a linear servo motor moved a curved shape into the range of the whiskers on the right side of the mouse\u2019s face. The shape stopped at one of three different positions (close, medium, or far). Even at the closest position, mice always had to actively move their whiskers in order to touch the shape. Mice performed this task in the dark, and we ensured that they relied on whisker-mediated touch to perform the task.\n\nMice could move their whiskers, make contacts on the shape, and lick left or right at any time during the trial. We took as their \u201cchoice lick\u201d the first lick that occurred in a period of time called the \u201cresponse window\u201d, which began exactly 2 seconds after the linear servo motor started moving the shape toward the mouse. If we define t = 0 as the opening of the response window, then the shape begins moving toward the mouse at t = -2 s, and reaches its final position between -0.8 s and -0.4 s, depending on whether the final position was close, medium, or far.\n\nAlthough we monitored all licks that mice made, all licks before the response window were irrelevant to the outcome of the trial. Only the first lick (left or right) during the response window determined the trial outcome (correct or incorrect). Correct licks were rewarded with water and incorrect licks were punished with a timeout, typically 9 seconds long.\n\nMice have five rows of whiskers, which are overlapping and difficult to distinguish in video. To permit unambiguous identification of whisker identity, we trimmed off all whiskers except the middle row, called the \u201cC row\u201d of whiskers. Within this row of whiskers, the longest and most posterior whisker is called C1, whereas the shortest and most anterior whisker still capable of reaching the shapes is called C3. We also tracked a longer and more posterior \u201cstraddler\u201d whisker (beta or gamma, but referred to here as C0 for simplicity), but this whisker rarely made contact with the shapes in most mice.\n\nThe two tasks (discrimination and detection) were designed to be as similar as possible, other than the task rule. For each task, we used the same behavioral equipment, shape stimuli, trial timing, behavioral shaping, and whisker trimming procedures. The only difference between the tasks was the rule governing the correct response given the presented stimulus.\n\nAs described in our previous publication6, the original experiments were conducted at Columbia University, under the supervision and approval of the Columbia University Institutional Animal Care and Use Committee. We purchased breeder mice from the C57BL/6J strain (Jackson Laboratories Stock #000664), but all mice reported here were bred in-house. Mice began behavioral training between postnatal days 90 and 180. They were kept on a 12 hour, non-reversed light cycle and were typically tested during the day. They were typically group-housed with littermates until neural recordings began, and then they were singly-housed to protect the implant. They were provided with a running saucer (Bio-Serv InnoDome) for enrichment. Mice were assigned arbitrarily to shape discrimination or shape detection tasks. We used males and females arbitrarily and in roughly equal proportion. Female mice typically weighed less than male mice and drank correspondingly less water, but we adjusted the reward size based on weight to achieve roughly equal trial counts. Because we observed no other differences, we pooled the data from both sexes. During spike sorting and pose tracking, we were blinded to the trial outcomes, though not to task type or mouse identity.\n"
}